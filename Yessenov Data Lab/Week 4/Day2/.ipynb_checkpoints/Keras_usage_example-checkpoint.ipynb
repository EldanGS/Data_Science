{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [this example from Francois Chollet](https://github.com/fchollet/keras/blob/master/examples/reuters_mlp.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Keras - библиотека с открытым кодом для разработки нейронный сетей. Ее автор Франсуа Шолле. Изначально задумывалась как надстройка над Theano, но теперь по умолчанию используется TensorFlow.\n",
    "\n",
    "<img src=\"Images/Keras_Logo.jpg\" style=\"width:200px;height:200px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка\n",
    "Установка Keras чрезвычайно проста, т.к. он является обычным питоновским пакетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы работать с Keras, у вас уже должен быть установлен хотя бы один из фреймворков — Theano или Tensorflow.\n",
    "Бэкенды — это то, из-за чего Keras стал известен и популярен (помимо прочих достоинств, которые мы разберем ниже). Keras позволяет использовать в качестве бэкенда разные другие фреймворки. При этом написанный вами код будет исполняться независимо от используемого бэкенда. Начиналась разработка, как мы уже говорили, с Theano, но со временем добавился Tensorflow и CNTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практический пример\n",
    "## Данные\n",
    "Обучение любой модели в машинном обучении начинается с данных. Keras содержит внутри несколько обучающих датасетов, но они уже приведены в удобную для работы форму и не позволяют показать всю мощь Keras. Поэтому мы возьмем более сырой датасет. Это будет датасет 20 newsgroups — 20 тысяч новостных сообщений из групп Usenet (это такая система обмена почтой родом из 1990-х) примерно поровну распределенных по 20 категориям. Мы будем учить нашу сеть правильно распределять сообщения по этим новостным группам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marina\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "7532\n"
     ]
    }
   ],
   "source": [
    "print(len(newsgroups_train[\"data\"]))\n",
    "print(len(newsgroups_test[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train[\"data\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предпроцессинг\n",
    "Keras содержит в себе инструменты для удобного препроцессинга текстов, картинок и временных рядов, иными словами, самых распространенных типов данных. В этом туториале мы работаем с текстами, поэтому нам нужно разбить их на токены и привести в матричную форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the Tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "print(\"Preparing the Tokenizer...\")\n",
    "max_words = 1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(newsgroups_train[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "x_train shape: (11314, 1000)\n",
      "x_test shape: (7532, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "x_train = tokenizer.texts_to_matrix(newsgroups_train[\"data\"], mode='binary')\n",
    "x_test = tokenizer.texts_to_matrix(newsgroups_test[\"data\"], mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще нам понадобится преобразовать метки классов к матричному виду для обучения с помощью кросс-энтропии. Для этого мы переведем номер класса в так называемый one-hot вектор, т.е. вектор, состоящий из нулей и одной единицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 classes\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(newsgroups_train[\"target\"]) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (11314, 20)\n",
      "y_test shape: (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(newsgroups_train[\"target\"], num_classes)\n",
    "y_test = keras.utils.to_categorical(newsgroups_test[\"target\"], num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель\n",
    "Модель в Keras можно описать двумя основными способами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API\n",
    "\n",
    "Первый — последовательное описание модели, например, вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model sequentially 1...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "print('Building model sequentially 1...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Building model sequentially 2...')\n",
    "model = Sequential([\n",
    "          Dense(512, input_shape=(max_words,)),\n",
    "          Activation('relu'),\n",
    "          Dropout(0.5),\n",
    "          Dense(num_classes),\n",
    "          Activation('softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "\n",
    "Некоторое время назад появилась возможность использовать функциональное API для создания модели — второй способ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model functionally...\n"
     ]
    }
   ],
   "source": [
    "print('Building model functionally...')\n",
    "a = Input(shape=(max_words,))\n",
    "b = Dense(512)(a)\n",
    "b = Activation('relu')(b)\n",
    "b = Dropout(0.5)(b)\n",
    "b = Dense(num_classes)(b)\n",
    "b = Activation('softmax')(b)\n",
    "model = Model(inputs=a, outputs=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс Model (и унаследованный от него Sequential) имеет удобный интерфейс, позволяющий посмотреть, какие слои входят в модель — model.layers, входы — model.inputs, и выходы — model.outputs.\n",
    "\n",
    "Посмотреть количество параметров модели можно model.summary()\n",
    "\n",
    "\n",
    "Также очень удобный метод отображения и сохранения модели в человеко-читаемом виде — model.to_yaml. Можно инстанциировать модели из такого описания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 522,772\n",
      "Trainable params: 522,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "- class_name: Dense\n",
      "  config:\n",
      "    activation: linear\n",
      "    activity_regularizer: null\n",
      "    batch_input_shape: !!python/tuple [null, 1000]\n",
      "    bias_constraint: null\n",
      "    bias_initializer:\n",
      "      class_name: Zeros\n",
      "      config: {}\n",
      "    bias_regularizer: null\n",
      "    dtype: float32\n",
      "    kernel_constraint: null\n",
      "    kernel_initializer:\n",
      "      class_name: VarianceScaling\n",
      "      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\n",
      "    kernel_regularizer: null\n",
      "    name: dense_1\n",
      "    trainable: true\n",
      "    units: 512\n",
      "    use_bias: true\n",
      "- class_name: Activation\n",
      "  config: {activation: relu, name: activation_1, trainable: true}\n",
      "- class_name: Dropout\n",
      "  config: {name: dropout_1, noise_shape: null, rate: 0.5, seed: null, trainable: true}\n",
      "- class_name: Dense\n",
      "  config:\n",
      "    activation: linear\n",
      "    activity_regularizer: null\n",
      "    bias_constraint: null\n",
      "    bias_initializer:\n",
      "      class_name: Zeros\n",
      "      config: {}\n",
      "    bias_regularizer: null\n",
      "    kernel_constraint: null\n",
      "    kernel_initializer:\n",
      "      class_name: VarianceScaling\n",
      "      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\n",
      "    kernel_regularizer: null\n",
      "    name: dense_2\n",
      "    trainable: true\n",
      "    units: !!python/object/apply:numpy.core.multiarray.scalar\n",
      "    - !!python/object/apply:numpy.dtype\n",
      "      args: [i4, 0, 1]\n",
      "      state: !!python/tuple [3, <, null, null, null, -1, -1, 0]\n",
      "    - !!binary |\n",
      "      FAAAAA==\n",
      "    use_bias: true\n",
      "- class_name: Activation\n",
      "  config: {activation: softmax, name: activation_2, trainable: true}\n",
      "keras_version: 2.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "\n",
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)\n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка модели к работе\n",
    "Что означают параметры функции compile? loss — это функция ошибки, в нашем случае — это перекрестная энтропия, именно для нее мы подготавливали наши метки в виде матриц; optimizer — используемый оптимизатор, здесь мог бы быть обычный стохастический градиентный спуск, но Adam показывает лучшую сходимость на этой задаче; metrics — метрики, по которым считается качество модели, в нашем случае — это точность (accuracy), то есть доля верно угаданных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на то, что Keras содержит большинство популярных функций ошибки, для вашей задачи может потребоваться что-то уникальное. Чтобы сделать свой собственный loss, нужно немного: просто определить функцию, принимающую векторы правильных и предсказанных ответов и выдающую одно число на выход. Для тренировки сделаем свою функцию расчета перекрестной энтропии. Чтобы она чем-то отличалась, введем так называемый clipping — обрезание значений вектора сверху и снизу. Да, еще важное замечание: нестандартный loss может быть необходимо описывать в терминах нижележащего фреймворка, но мы можем обойтись средствами Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "epsilon = 1.0e-9\n",
    "def custom_objective(y_true, y_pred):\n",
    "    '''Yet another crossentropy'''\n",
    "    y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "    y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "    cce = categorical_crossentropy(y_pred, y_true)\n",
    "    return cce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=custom_objective,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение и тестирование\n",
    "\n",
    "Метод fit делает именно это. Он принимает на вход обучающую выборку вместе с метками — x_train и y_train, размером батча batch_size, который ограничивает количество примеров, подаваемых за раз, количеством эпох для обучения epochs (одна эпоха — это один раз полностью пройденная моделью обучающая выборка), а также тем, какую долю обучающей выборки отдать под валидацию — validation_split.\n",
    "\n",
    "Возвращает этот метод history — это история ошибок на каждом шаге обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 5s 529us/step - loss: 10.6697 - acc: 0.3935 - val_loss: 7.4356 - val_acc: 0.5928\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 5s 480us/step - loss: 6.6719 - acc: 0.6243 - val_loss: 5.9738 - val_acc: 0.6661\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 4s 436us/step - loss: 5.2289 - acc: 0.7081 - val_loss: 5.5104 - val_acc: 0.6837\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 4s 438us/step - loss: 4.5327 - acc: 0.7426 - val_loss: 5.3232 - val_acc: 0.6890\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 5s 513us/step - loss: 4.1579 - acc: 0.7617 - val_loss: 5.2844 - val_acc: 0.6890\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И наконец, тестирование. Метод evaluate получает на вход тестовую выборку вместе с метками для нее. Метрика была задана еще при подготовке к работе, так что больше ничего не нужно. (Но мы укажем еще размер батча)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "Нужно также сказать несколько слов о такой важной особенности Keras, как колбеки. Через них реализовано много полезной функциональности. Например, если вы тренируете сеть в течение очень долгого времени, вам нужно понять, когда пора остановиться, если ошибка на вашем датасете перестала уменьшаться. По-английски описываемая функциональность называется \"early stopping\" (\"ранняя остановка\"). Посмотрим, как мы можем применить его при обучении нашей сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc\n",
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/15\n",
      "11314/11314 [==============================] - 7s 620us/step - loss: 0.4577 - acc: 0.9720 - val_loss: 5.5979 - val_acc: 0.6545\n",
      "Epoch 2/15\n",
      "11314/11314 [==============================] - 7s 613us/step - loss: 0.4526 - acc: 0.9723 - val_loss: 5.4680 - val_acc: 0.6634\n",
      "Epoch 3/15\n",
      "11314/11314 [==============================] - 7s 631us/step - loss: 0.4543 - acc: 0.9722 - val_loss: 5.5714 - val_acc: 0.6556\n",
      "Epoch 4/15\n",
      "11314/11314 [==============================] - 7s 619us/step - loss: 0.4417 - acc: 0.9731 - val_loss: 5.4472 - val_acc: 0.6624\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "early_stopping=EarlyStopping(monitor='val_acc', patience=2, mode='max', min_delta=0.0001, verbose=1)  \n",
    "print(early_stopping.monitor)\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532/7532 [==============================] - 1s 97us/step\n",
      "\n",
      "\n",
      "Test score: 5.447168237024713\n",
      "Test accuracy: 0.6623738714816781\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Заключение\n",
    "\n",
    "Пришло время обсудить плюсы и минусы Keras. К очевидным плюсам можно отнести простоту создания моделей, которая выливается в высокую скорость прототипирования. В целом этот фреймворк становится все более и более популярным. Кажется, своей цели — простоты использования — Франсуа Шолле (François Chollet, автор Keras) добился. Более того, его инициатива не осталась незамеченной: буквально через несколько месяцев разработки компания Google пригласила его заниматься этим в команде, разрабатывающей Tensorflow. А также с версии Tensorflow 1.2 Keras был включен в состав TF (tf.keras).\n",
    "\n",
    "\n",
    "Также надо сказать пару слов о недостатках. К сожалению, идея Keras о универсальности кода выполняется не всегда: Keras 2.0 поломал совместимость с первой версией, некоторые функции стали называться по-другому, некоторые переехали, в общем, история похожа на второй и третий python. Отличием является то, что в случае Keras была выбрана только вторая версия для развития. Также код Keras работает на Tensorflow пока медленнее, чем на Theano (хотя для нативного кода фреймворки, как минимум, сравнимы).\n",
    "\n",
    "\n",
    "В целом, можно порекомендовать Keras к использованию, когда вам нужно быстро составить и протестировать сеть для решения конкретной задачи. Но если вам нужны какие-то сложные вещи, вроде нестандартного слоя или распараллеливания кода на несколько GPU, то лучше (а подчас просто неизбежно) использовать нижележащий фреймворк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
